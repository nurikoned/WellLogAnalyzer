# -*- coding: utf-8 -*-
"""App

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CehlEwPz1nguAsyS1yBoLCC57midBC-l
"""

pip install streamlit lasio pandas numpy scikit-learn xgboost matplotlib

import joblib
from xgboost import XGBClassifier # or XGBRegressor, depending on your task

model = joblib.load('model.pkl')

joblib.dump(model, 'model.pkl')

import streamlit as st
import lasio
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
import joblib
import matplotlib.pyplot as plt
from io import StringIO

# Set page title
st.title("Kansas Basin Well Log Analyzer")
st.markdown("Upload an LAS file to preprocess, predict lithology labels, and visualize the results.")

# Define features and lithology mapping
FEATURES = ['GR', 'RHOB', 'RILD', 'DT', 'SP']
LITHOLOGY_MAPPING = {0: 'Shale', 1: 'Dolomite', 2: 'Limestone', 3: 'Sandstone', 4: 'Siltstone'}

# File uploader for LAS file
uploaded_file = st.file_uploader("Upload an LAS file", type=['las'])

if uploaded_file is not None:
    # Read the LAS file
    st.subheader("Step 1: Reading the LAS File")
    las = lasio.read(uploaded_file)
    df = las.df().reset_index()  # Convert LAS to DataFrame
    st.write("Original Data Preview:")
    st.dataframe(df.head())

    # Check if required features are present
    missing_features = [f for f in FEATURES if f not in df.columns]
    if missing_features:
        st.error(f"Missing required features in LAS file: {missing_features}")
    else:
        # Preprocessing
        st.subheader("Step 2: Preprocessing the Data")

        # Handle missing values
        st.write("Handling missing values using median imputation...")
        imputer = SimpleImputer(strategy='median')
        df[FEATURES] = imputer.fit_transform(df[FEATURES])

        # Cap outliers in RILD at the 99th percentile
        st.write("Capping RILD outliers at the 99th percentile...")
        rild_99th = np.percentile(df['RILD'], 99)
        df['RILD'] = np.where(df['RILD'] > rild_99th, rild_99th, df['RILD'])

        # Scale features to [0, 1]
        st.write("Scaling features to [0, 1] range...")
        scaler = MinMaxScaler()
        df[FEATURES] = scaler.fit_transform(df[FEATURES])

        st.write("Preprocessed Data Preview:")
        st.dataframe(df.head())

        # Predict lithology labels
        st.subheader("Step 3: Predicting Lithology Labels")
        try:
            model = joblib.load('model.pkl')
            st.write("Loaded pre-trained XGBoost model.")
        except FileNotFoundError:
            st.error("Pre-trained model 'model.pkl' not found. Please ensure the model file is in the same directory as this script.")
            st.stop()

        # Make predictions
        X = df[FEATURES]
        predictions = model.predict(X)
        df['LITHOLOGY'] = [LITHOLOGY_MAPPING[pred] for pred in predictions]
        st.write("Data with Predicted Lithology Labels:")
        st.dataframe(df.head())

        # Create new LAS file with predictions
        st.subheader("Step 4: Generating Output LAS File")
        las_out = lasio.LASFile()

        # Copy metadata from original LAS file
        las_out.well = las.well
        las_out.curves = las.curves
        las_out.params = las.params
        las_out.other = las.other

        # Add depth and features to the new LAS file
        las_out.append_curve('DEPT', df['DEPT'], unit='FT', descr='Depth')
        for feature in FEATURES:
            las_out.append_curve(feature, df[feature], unit=las.curves[feature].unit, descr=las.curves[feature].descr)

        # Add predicted lithology as a new curve
        las_out.append_curve('LITHOLOGY', predictions, unit='', descr='Predicted Lithology (0=Shale, 1=Dolomite, 2=Limestone, 3=Sandstone, 4=Siltstone)')

        # Convert LAS to string for download
        las_string = StringIO()
        las_out.write(las_string)
        las_string.seek(0)

        # Provide download button for the new LAS file
        st.download_button(
            label="Download LAS File with Lithology Labels",
            data=las_string.getvalue(),
            file_name="output_with_lithology.las",
            mime="text/plain"
        )

        # Plotting
        st.subheader("Step 5: Visualizing Well Logs and Lithology")
        fig, axes = plt.subplots(nrows=1, ncols=len(FEATURES) + 1, figsize=(15, 10), sharey=True)

        # Plot each feature
        for i, feature in enumerate(FEATURES):
            axes[i].plot(df[feature], df['DEPT'], label=feature)
            axes[i].set_title(feature)
            axes[i].invert_yaxis()
            axes[i].grid(True)
            if i == 0:
                axes[i].set_ylabel('Depth (ft)')

        # Plot lithology
        lith_colors = {'Shale': 'gray', 'Dolomite': 'blue', 'Limestone': 'green', 'Sandstone': 'yellow', 'Siltstone': 'red'}
        lith_numeric = df['LITHOLOGY'].map({v: k for k, v in LITHOLOGY_MAPPING.items()})
        axes[-1].scatter(lith_numeric, df['DEPT'], c=df['LITHOLOGY'].map(lith_colors), label='Lithology')
        axes[-1].set_title('Lithology')
        axes[-1].set_xticks(range(len(LITHOLOGY_MAPPING)))
        axes[-1].set_xticklabels(LITHOLOGY_MAPPING.values(), rotation=45)
        axes[-1].invert_yaxis()
        axes[-1].grid(True)

        plt.tight_layout()
        st.pyplot(fig)

else:
    st.info("Please upload an LAS file to begin.")

